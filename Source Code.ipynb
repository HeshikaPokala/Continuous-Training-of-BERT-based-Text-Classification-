{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36573514-05a9-4702-97b2-d36318c52f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  label\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
      "1  Homelessness (or Houselessness as George Carli...      1\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
      "3  This is easily the most underrated film inn th...      1\n",
      "4  This is not the typical Mel Brooks film. It wa...      1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_directory(directory):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(directory, label)\n",
    "        label_value = 1 if label == 'pos' else 0\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.txt'):  # Ensure we only read text files\n",
    "                with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "                    reviews.append(f.read())\n",
    "                    labels.append(label_value)\n",
    "\n",
    "    return pd.DataFrame({'review': reviews, 'label': labels})\n",
    "\n",
    "# Load the training and testing data\n",
    "train_df = load_data_from_directory('IMDB/train')\n",
    "test_df = load_data_from_directory('IMDB/test')\n",
    "\n",
    "# Display the first few rows of the training dataset\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93eedf7-7db4-4277-bcb6-424f7a38e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f47b41c-8fa9-4a87-a873-1dda6f733ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers (optional)\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a00b1be-b65c-401a-820a-443a62b4e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_directory(directory):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(directory, label)  # Using the directory parameter\n",
    "        label_value = 1 if label == 'pos' else 0\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "                    reviews.append(f.read())\n",
    "                    labels.append(label_value)\n",
    "\n",
    "    return pd.DataFrame({'review': reviews, 'label': labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d4cfc3-0789-48b0-a06f-b123223e3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data_from_directory('IMDB/train')\n",
    "test_df = load_data_from_directory('IMDB/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8182fe8-eba5-4cf5-94bc-efa8bba84326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review'] = train_df['review'].apply(clean_text)\n",
    "test_df['review'] = test_df['review'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c87aaa-6958-4e15-b7f1-b0228624814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwell high is a cartoon comedy it ran at th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homelessness or houselessness as george carlin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brilliant overacting by lesley ann warren best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is not the typical mel brooks film it was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  bromwell high is a cartoon comedy it ran at th...      1\n",
       "1  homelessness or houselessness as george carlin...      1\n",
       "2  brilliant overacting by lesley ann warren best...      1\n",
       "3  this is easily the most underrated film inn th...      1\n",
       "4  this is not the typical mel brooks film it was...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e7086dd-e64e-4906-85c4-6443ab55d713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor turned director bill paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i saw this film in a sneak preview and it is d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill paxton has taken the true story of the us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  i went and saw this movie last night after bei...      1\n",
       "1  actor turned director bill paxton follows up h...      1\n",
       "2  as a recreational golfer with some knowledge o...      1\n",
       "3  i saw this film in a sneak preview and it is d...      1\n",
       "4  bill paxton has taken the true story of the us...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c71537-1aac-47ec-9701-939c84ef9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e99b03-7d02-4fcc-ad84-b13e7ab9bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.batch_encode_plus(\n",
    "    train_df['review'].tolist(),\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550f0ff1-189e-48d7-ab99-14328e53230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = tokens['input_ids']\n",
    "train_attention_mask = tokens['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba83d3e7-c741-4b9a-883b-9dc134b73520",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(train_df['label'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbd840a4-64f0-4ab2-aa96-b705db26b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741d9fa7-7f92-4b78-b366-2e904a87dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IMDBDataset(train_input_ids, train_attention_mask, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9ffdc44-0ab4-42ae-8d00-4758452d284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = tokenizer.batch_encode_plus(\n",
    "    test_df['review'].tolist(),\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ad0fa4f-6d51-4a7b-994b-a36eb687ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids = test_tokens['input_ids']\n",
    "test_attention_mask = test_tokens['attention_mask']\n",
    "test_labels = torch.tensor(test_df['label'].tolist())\n",
    "\n",
    "# Create the testing dataset\n",
    "test_dataset = IMDBDataset(test_input_ids, test_attention_mask, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6866bdc-d9d8-4655-a487-f51539576f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2ba01-8697-47e4-9acf-a3262da49ef1",
   "metadata": {},
   "source": [
    "# Preparing our dataset for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e92d659-f9c8-4fa1-bb86-37d08a5f055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\kumar_lf3uub3\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 782/782 [5:57:11<00:00, 27.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.3356241104776597\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 782/782 [5:58:30<00:00, 27.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.20139865181349276\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 782/782 [5:55:19<00:00, 27.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.10194295275982593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(3):  # Set the number of epochs\n",
    "    print(f'Epoch {epoch + 1}/{3}')\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        # Move data to GPU if available\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "    \n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Average Training Loss: {avg_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cb6267e-5a2d-41e6-990f-b35c7a6108a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to bert_model and bert_tokenizer\n"
     ]
    }
   ],
   "source": [
    "model_save_path = 'bert_model'\n",
    "tokenizer_save_path = 'bert_tokenizer'\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "# Save the tokenizer (assumed it's already initialized)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "print(f'Model and tokenizer saved to {model_save_path} and {tokenizer_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a87518-393b-451a-b4b9-16db7d8ec1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MODEL BECAUSE TRAINING IS OVER AND MODEL IS SAVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28d78baa-d3b5-4ef1-91f9-8d5b2e280609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Accuracy: 0.8800\n",
      "KS Statistic: 0.0000, P-value: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "\n",
    "# Step 5: Model Monitoring with Progress\n",
    "class ModelMonitor:\n",
    "    def __init__(self, model, test_loader, accuracy_threshold=0.85, drift_threshold=0.05, sample_fraction=0.2):\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.last_accuracy = 0\n",
    "        self.accuracy_threshold = accuracy_threshold\n",
    "        self.drift_threshold = drift_threshold\n",
    "        self.sample_fraction = sample_fraction\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        # Sample a subset of test_loader for evaluation\n",
    "        total_samples = len(self.test_loader.dataset)\n",
    "        sample_size = int(total_samples * self.sample_fraction)\n",
    "        sampled_indices = np.random.choice(total_samples, sample_size, replace=False)\n",
    "        sampled_test_loader = DataLoader(Subset(self.test_loader.dataset, sampled_indices), batch_size=self.test_loader.batch_size)\n",
    "\n",
    "        # Model evaluation\n",
    "        self.model.eval()\n",
    "        predictions, true_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in self.test_loader:\n",
    "                b_input_ids = batch['input_ids'].to(device)\n",
    "                b_attention_mask = batch['attention_mask'].to(device)\n",
    "                b_labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = self.model(b_input_ids, attention_mask=b_attention_mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1).flatten()\n",
    "                \n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "                true_labels.extend(b_labels.cpu().numpy())\n",
    "\n",
    "        accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "        print(f\"Sampled Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Check for accuracy drop\n",
    "        if accuracy < self.accuracy_threshold:\n",
    "            print(\"Model accuracy is below threshold, retraining recommended!\")\n",
    "            return True  # Indicates that retraining is recommended\n",
    "\n",
    "        self.last_accuracy = accuracy\n",
    "        return False  # No retraining needed\n",
    "\n",
    "# Step 6: Data Drift Detection with Progress\n",
    "class DataDriftMonitor:\n",
    "    def __init__(self, training_data, threshold=0.05):\n",
    "        self.training_data = training_data\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def check_drift(self, new_data):\n",
    "        ks_statistic, p_value = stats.ks_2samp(self.training_data, new_data)\n",
    "        print(f\"KS Statistic: {ks_statistic:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "        if p_value < self.threshold:\n",
    "            print(\"Data drift detected, retraining recommended!\")\n",
    "            return True  # Indicates that retraining is recommended\n",
    "\n",
    "        return False  # No drift detected\n",
    "\n",
    "# Step 7: Monitor and Retrain with Progress\n",
    "monitor = ModelMonitor(model, test_loader)\n",
    "needs_retraining = monitor.evaluate_model()\n",
    "\n",
    "# Assume we get new incoming data for checking drift\n",
    "new_data = train_df['review']  # Replace this with the actual new data\n",
    "drift_monitor = DataDriftMonitor(train_df['review'].tolist())\n",
    "data_drift_detected = drift_monitor.check_drift(new_data)\n",
    "\n",
    "if needs_retraining or data_drift_detected:\n",
    "    print(\"Initiating retraining process...\")\n",
    "    for epoch in range(epochs):  # Specify epochs\n",
    "        train_model(model, train_loader, optimizer, epochs=1)\n",
    "    \n",
    "    model.save_pretrained('./new_model_ps1')\n",
    "    tokenizer.save_pretrained('./new_tokenizer_ps1')\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.pytorch.log_model(model, \"new_model_ps1\")  # Log the model\n",
    "        mlflow.log_metric(\"accuracy\", monitor.last_accuracy)  # Log accuracy\n",
    "        mlflow.log_param(\"retraining_due_to\", \"accuracy drop\" if needs_retraining else \"data drift\")  # Reason for retraining\n",
    "        print(\"New model version logged to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5afbb6a9-36bb-433c-9e08-5d9cc1e32407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c1c1d7-4182-42a3-b740-c5b1cc886c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 0\n",
      "Current Model Accuracy: 0.00\n",
      "Accuracy below threshold, retraining model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar_lf3uub3\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fine-tuned and updated.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define device, model, tokenizer, and accuracy threshold\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained('./bert_model').to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_tokenizer')\n",
    "model.eval()  # Set model to evaluation mode\n",
    "accuracy_threshold = 0.8  # Define your accuracy threshold\n",
    "\n",
    "# Path to log file\n",
    "log_path = 'user_inputs_log.csv'\n",
    "\n",
    "# Function to log user inputs\n",
    "def log_user_input(text, true_label):\n",
    "    log_exists = os.path.isfile(log_path)\n",
    "    df = pd.DataFrame([[text, true_label]], columns=['text', 'label'])\n",
    "    df.to_csv(log_path, mode='a', header=not log_exists, index=False)\n",
    "\n",
    "# Function to preprocess text and predict label\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return predicted_label\n",
    "\n",
    "# Function to calculate accuracy on logged data\n",
    "def evaluate_accuracy():\n",
    "    if not os.path.isfile(log_path):\n",
    "        return 1.0  # Return perfect accuracy if no data yet\n",
    "    \n",
    "    data = pd.read_csv(log_path)\n",
    "    texts = data['text'].tolist()\n",
    "    true_labels = data['label'].tolist()\n",
    "    predicted_labels = [predict(text) for text in texts]\n",
    "    return accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Function to fine-tune model based on logged data\n",
    "def fine_tune_model():\n",
    "    # Load logged data for retraining\n",
    "    data = pd.read_csv(log_path)\n",
    "    texts = data['text'].tolist()\n",
    "    labels = data['label'].tolist()\n",
    "    \n",
    "    # Tokenize inputs\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    labels = torch.tensor(labels).to(device)\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    # Fine-tune for a small number of epochs\n",
    "    epochs = 3\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Save the updated model\n",
    "    model.save_pretrained('updated_bert_model')\n",
    "    model.eval()  # Return model to evaluation mode\n",
    "    print(\"Model fine-tuned and updated.\")\n",
    "\n",
    "# Main function to handle user input, prediction, logging, and evaluation\n",
    "def handle_user_input(text, true_label):\n",
    "    # Log the input\n",
    "    log_user_input(text, true_label)\n",
    "    \n",
    "    # Predict and display prediction accuracy\n",
    "    predicted_label = predict(text)\n",
    "    accuracy = evaluate_accuracy()\n",
    "    print(f\"Predicted Label: {predicted_label}\")\n",
    "    print(f\"Current Model Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    # Retrain if accuracy drops below threshold\n",
    "    if accuracy < accuracy_threshold:\n",
    "        print(\"Accuracy below threshold, retraining model...\")\n",
    "        fine_tune_model()\n",
    "\n",
    "# Example usage with sample inputs\n",
    "handle_user_input(\"Sample text for testing.\", true_label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92856cc0-1cb1-421c-b6f3-88adcb0270fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full code\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_directory(directory):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(directory, label)\n",
    "        label_value = 1 if label == 'pos' else 0\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.txt'):  # Ensure we only read text files\n",
    "                with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "                    reviews.append(f.read())\n",
    "                    labels.append(label_value)\n",
    "\n",
    "    return pd.DataFrame({'review': reviews, 'label': labels})\n",
    "\n",
    "# Load the training and testing data\n",
    "train_df = load_data_from_directory('IMDB/train')\n",
    "test_df = load_data_from_directory('IMDB/test')\n",
    "\n",
    "# Display the first few rows of the training dataset\n",
    "print(train_df.head())\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers (optional)\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n",
    "def load_data_from_directory(directory):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(directory, label)  # Using the directory parameter\n",
    "        label_value = 1 if label == 'pos' else 0\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "                    reviews.append(f.read())\n",
    "                    labels.append(label_value)\n",
    "\n",
    "    return pd.DataFrame({'review': reviews, 'label': labels})\n",
    "train_df = load_data_from_directory('IMDB/train')\n",
    "test_df = load_data_from_directory('IMDB/test')\n",
    "train_df['review'] = train_df['review'].apply(clean_text)\n",
    "test_df['review'] = test_df['review'].apply(clean_text)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokens = tokenizer.batch_encode_plus(\n",
    "    train_df['review'].tolist(),\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "train_input_ids = tokens['input_ids']\n",
    "train_attention_mask = tokens['attention_mask']\n",
    "train_labels = torch.tensor(train_df['label'].tolist())\n",
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "train_dataset = IMDBDataset(train_input_ids, train_attention_mask, train_labels)\n",
    "test_tokens = tokenizer.batch_encode_plus(\n",
    "    test_df['review'].tolist(),\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "test_input_ids = test_tokens['input_ids']\n",
    "test_attention_mask = test_tokens['attention_mask']\n",
    "test_labels = torch.tensor(test_df['label'].tolist())\n",
    "\n",
    "# Create the testing dataset\n",
    "test_dataset = IMDBDataset(test_input_ids, test_attention_mask, test_labels)\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(3):  # Set the number of epochs\n",
    "    print(f'Epoch {epoch + 1}/{3}')\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        # Move data to GPU if available\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "    \n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Average Training Loss: {avg_loss}')\n",
    "model_save_path = 'bert_model'\n",
    "tokenizer_save_path = 'bert_tokenizer'\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "# Save the tokenizer (assumed it's already initialized)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "print(f'Model and tokenizer saved to {model_save_path} and {tokenizer_save_path}')\n",
    "import mlflow\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "\n",
    "# Step 5: Model Monitoring with Progress\n",
    "class ModelMonitor:\n",
    "    def __init__(self, model, test_loader, accuracy_threshold=0.85, drift_threshold=0.05, sample_fraction=0.2):\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.last_accuracy = 0\n",
    "        self.accuracy_threshold = accuracy_threshold\n",
    "        self.drift_threshold = drift_threshold\n",
    "        self.sample_fraction = sample_fraction\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        # Sample a subset of test_loader for evaluation\n",
    "        total_samples = len(self.test_loader.dataset)\n",
    "        sample_size = int(total_samples * self.sample_fraction)\n",
    "        sampled_indices = np.random.choice(total_samples, sample_size, replace=False)\n",
    "        sampled_test_loader = DataLoader(Subset(self.test_loader.dataset, sampled_indices), batch_size=self.test_loader.batch_size)\n",
    "\n",
    "        # Model evaluation\n",
    "        self.model.eval()\n",
    "        predictions, true_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in self.test_loader:\n",
    "                b_input_ids = batch['input_ids'].to(device)\n",
    "                b_attention_mask = batch['attention_mask'].to(device)\n",
    "                b_labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = self.model(b_input_ids, attention_mask=b_attention_mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1).flatten()\n",
    "                \n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "                true_labels.extend(b_labels.cpu().numpy())\n",
    "\n",
    "        accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "        print(f\"Sampled Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Check for accuracy drop\n",
    "        if accuracy < self.accuracy_threshold:\n",
    "            print(\"Model accuracy is below threshold, retraining recommended!\")\n",
    "            return True  # Indicates that retraining is recommended\n",
    "\n",
    "        self.last_accuracy = accuracy\n",
    "        return False  # No retraining needed\n",
    "\n",
    "# Step 6: Data Drift Detection with Progress\n",
    "class DataDriftMonitor:\n",
    "    def __init__(self, training_data, threshold=0.05):\n",
    "        self.training_data = training_data\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def check_drift(self, new_data):\n",
    "        ks_statistic, p_value = stats.ks_2samp(self.training_data, new_data)\n",
    "        print(f\"KS Statistic: {ks_statistic:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "        if p_value < self.threshold:\n",
    "            print(\"Data drift detected, retraining recommended!\")\n",
    "            return True  # Indicates that retraining is recommended\n",
    "\n",
    "        return False  # No drift detected\n",
    "\n",
    "# Step 7: Monitor and Retrain with Progress\n",
    "monitor = ModelMonitor(model, test_loader)\n",
    "needs_retraining = monitor.evaluate_model()\n",
    "\n",
    "# Assume we get new incoming data for checking drift\n",
    "new_data = train_df['review']  # Replace this with the actual new data\n",
    "drift_monitor = DataDriftMonitor(train_df['review'].tolist())\n",
    "data_drift_detected = drift_monitor.check_drift(new_data)\n",
    "\n",
    "if needs_retraining or data_drift_detected:\n",
    "    print(\"Initiating retraining process...\")\n",
    "    for epoch in range(epochs):  # Specify epochs\n",
    "        train_model(model, train_loader, optimizer, epochs=1)\n",
    "    \n",
    "    model.save_pretrained('./new_model_ps1')\n",
    "    tokenizer.save_pretrained('./new_tokenizer_ps1')\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.pytorch.log_model(model, \"new_model_ps1\")  # Log the model\n",
    "        mlflow.log_metric(\"accuracy\", monitor.last_accuracy)  # Log accuracy\n",
    "        mlflow.log_param(\"retraining_due_to\", \"accuracy drop\" if needs_retraining else \"data drift\")  # Reason for retraining\n",
    "        print(\"New model version logged to MLflow\")\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define device, model, tokenizer, and accuracy threshold\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained('./bert_model').to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_tokenizer')\n",
    "model.eval()  # Set model to evaluation mode\n",
    "accuracy_threshold = 0.8  # Define your accuracy threshold\n",
    "\n",
    "# Path to log file\n",
    "log_path = 'user_inputs_log.csv'\n",
    "\n",
    "# Function to log user inputs\n",
    "def log_user_input(text, true_label):\n",
    "    log_exists = os.path.isfile(log_path)\n",
    "    df = pd.DataFrame([[text, true_label]], columns=['text', 'label'])\n",
    "    df.to_csv(log_path, mode='a', header=not log_exists, index=False)\n",
    "\n",
    "# Function to preprocess text and predict label\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return predicted_label\n",
    "\n",
    "# Function to calculate accuracy on logged data\n",
    "def evaluate_accuracy():\n",
    "    if not os.path.isfile(log_path):\n",
    "        return 1.0  # Return perfect accuracy if no data yet\n",
    "    \n",
    "    data = pd.read_csv(log_path)\n",
    "    texts = data['text'].tolist()\n",
    "    true_labels = data['label'].tolist()\n",
    "    predicted_labels = [predict(text) for text in texts]\n",
    "    return accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Function to fine-tune model based on logged data\n",
    "def fine_tune_model():\n",
    "    # Load logged data for retraining\n",
    "    data = pd.read_csv(log_path)\n",
    "    texts = data['text'].tolist()\n",
    "    labels = data['label'].tolist()\n",
    "    \n",
    "    # Tokenize inputs\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    labels = torch.tensor(labels).to(device)\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    # Fine-tune for a small number of epochs\n",
    "    epochs = 3\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Save the updated model\n",
    "    model.save_pretrained('updated_bert_model')\n",
    "    model.eval()  # Return model to evaluation mode\n",
    "    print(\"Model fine-tuned and updated.\")\n",
    "\n",
    "# Main function to handle user input, prediction, logging, and evaluation\n",
    "def handle_user_input(text, true_label):\n",
    "    # Log the input\n",
    "    log_user_input(text, true_label)\n",
    "    \n",
    "    # Predict and display prediction accuracy\n",
    "    predicted_label = predict(text)\n",
    "    accuracy = evaluate_accuracy()\n",
    "    print(f\"Predicted Label: {predicted_label}\")\n",
    "    print(f\"Current Model Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    # Retrain if accuracy drops below threshold\n",
    "    if accuracy < accuracy_threshold:\n",
    "        print(\"Accuracy below threshold, retraining model...\")\n",
    "        fine_tune_model()\n",
    "\n",
    "# Example usage with sample inputs\n",
    "handle_user_input(\"Sample text for testing.\", true_label=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd02ec0-a396-4f21-bc08-640bac216366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a0ce3-f202-479b-9cbd-7e83d631ba9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
